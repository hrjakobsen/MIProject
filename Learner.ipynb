{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hexagon game Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of the hexagon game written in a functional (stateless) style so that we can simulate actions in our Q-learner without changing the actual game board.\n",
    "\n",
    "For storing the game board we use a numpy array instead of python lists, to make some of the operations less costly, as there is a lot of copying arrays going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def randomGame(width, height):\n",
    "    board = np.random.randint(5, size=(height + 1, width))\n",
    "    \n",
    "    # What we actually want is a jagged array where the odd cols \n",
    "    # are shifted half a cell up, to simulate a hexagon grid.\n",
    "    # We achieve this by making the grid 1 higher than specified and \n",
    "    # 'remove' the top cell in the odd columns\n",
    "    for x in range(width // 2):\n",
    "        board[0][x * 2 + 1] = -1\n",
    "        \n",
    "    # Set the initial player positions\n",
    "    board[0, 0] = 5\n",
    "    board[height, width - 1] = 10\n",
    "    \n",
    "    return board\n",
    "\n",
    "def getHash(board):\n",
    "    # This function generates a unique hash for each board\n",
    "    # This is done by realising that each cell on the board\n",
    "    # can be in one of 7 (5 colors + owned by either player)\n",
    "    # This means that each cell can be stored in a single character\n",
    "    # 0-4 (colors), a (owned by player 1) and b (owned by player 2)\n",
    "       \n",
    "    lookUp = ['0', '1', '2', '3', '4', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', '']\n",
    "    return ''.join([lookUp[int(i)] for i in np.nditer(board.T)])\n",
    "\n",
    "def makeMove(board, player, action):\n",
    "    # Do everything on a copy to ensure stateless-ness\n",
    "    board = board.copy()\n",
    "    \n",
    "    height = board.shape[0]\n",
    "    width = board.shape[1]\n",
    "    \n",
    "    frontier = getOwnedCells(board, player)\n",
    "    \n",
    "    # Our color can spread through cells that were just added\n",
    "    # so we maintain a frontier that is the cells that we still\n",
    "    # need to check for neighbors of the right colour\n",
    "    while len(frontier):\n",
    "        point = frontier.pop()\n",
    "        board[point[0], point[1]] = action + player * 5\n",
    "        \n",
    "        neighbours = pointsAround(point)\n",
    "        \n",
    "        # Find the neighbours that are inside the board and\n",
    "        # have the color of the action and add them to the frontier \n",
    "        for neighbour in neighbours:\n",
    "            if (0 <= neighbour[0] < height \n",
    "                and 0 <= neighbour[1] < width \n",
    "                and board[neighbour[0], neighbour[1]] != -1 \n",
    "                and board[neighbour[0], neighbour[1]] == action):\n",
    "                frontier.append(neighbour)\n",
    "    \n",
    "    # If a player has no more moves, the other player is rewarded\n",
    "    # the rest of the cells on the board\n",
    "    board = finaliseBoard(board, player)\n",
    "    return board\n",
    "\n",
    "def getOwnedCells(board, player):\n",
    "    lowerLimit = player * 5\n",
    "    upperLimit = (player + 1) * 5\n",
    "    \n",
    "    frontier = list(\n",
    "        np.column_stack(\n",
    "            np.where(\n",
    "                np.logical_and(board < upperLimit, board >= lowerLimit)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return frontier\n",
    "\n",
    "def finaliseBoard(board, playerCall):\n",
    "    board = board.copy()\n",
    "    player = 2 if playerCall == 1 else 1\n",
    "    frontier = getOwnedCells(board, player)\n",
    "    height = board.shape[0]\n",
    "    width = board.shape[1]\n",
    "    \n",
    "    playerColor = board[0, 0] if playerCall == 1 else board[height - 1, width - 1]\n",
    "    found = False\n",
    "    \n",
    "    # Check if the player has a valid action that gains more cells\n",
    "    for cell in frontier:\n",
    "        neighbours = pointsAround(cell)\n",
    "        for neighbour in neighbours:\n",
    "            if (0 <= neighbour[0] < height \n",
    "                and 0 <= neighbour[1] < width \n",
    "                and 0 <= board[neighbour[0], neighbour[1]] < 5):\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    if found:\n",
    "        return board\n",
    "    \n",
    "    # Award the player the rest of the cells\n",
    "    for x in np.nditer(board, op_flags=['readwrite']):\n",
    "        if 0 <= int(x) < 5:\n",
    "            x[...] = playerColor\n",
    "    return board\n",
    "\n",
    "def getReward(game, player):\n",
    "    # This function calculates the reward of a game\n",
    "    # We reward nothing for a move unless it is a winning move\n",
    "    # Then it gains 1 point. If it is a losing move, it gains -1\n",
    "    if not gameEnded(game):\n",
    "        return -0.04\n",
    "\n",
    "    height = game.shape[0]\n",
    "    width = game.shape[1]\n",
    "    \n",
    "    player1Color = game[0,0]\n",
    "    player2Color = game[height - 1, width - 1]\n",
    "    player1count = np.count_nonzero(game == player1Color)\n",
    "    player2count = np.count_nonzero(game == player2Color)\n",
    "    \n",
    "    if player == 1:\n",
    "        if player1count > player2count:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        if player2count > player1count:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "def gameEnded(board):\n",
    "    # Simply checks if there are any cells that is not owned \n",
    "    return not np.any(np.logical_and(board >= 0, board < 5))\n",
    "        \n",
    "def pointsAround(point):\n",
    "    y, x = point[0], point[1]\n",
    "    relOddCoords = [\n",
    "        (-1, 0),\n",
    "        (-1, 1),\n",
    "        (0, 1),\n",
    "        (1, 0),\n",
    "        (0, -1),\n",
    "        (-1, -1)\n",
    "    ]\n",
    "\n",
    "    relEvenCoords = [\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (1, 1),\n",
    "        (1, 0),\n",
    "        (1, -1),\n",
    "        (0, -1)\n",
    "    ]\n",
    "    \n",
    "    odd = x % 2 == 1\n",
    "    \n",
    "    neighbours = []\n",
    "    for coord in relOddCoords if odd else relEvenCoords:\n",
    "        newY = y + coord[0]\n",
    "        newX = x + coord[1]\n",
    "        neighbours.append([newY, newX])\n",
    "    return neighbours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below is an implementaiton of the Q-Learning-Agent from Russel & Norvig (2010) that maintains a State-Action array $Q$ and uses it to learns the best actions from the reward $r$ of a given state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def saveToFile(dict, fileName):\n",
    "    with open(fileName, 'w') as fp:\n",
    "        json.dump({str(k): v for k, v in dict.items()}, fp)\n",
    "\n",
    "def loadFromFile(fileName):\n",
    "    with open(fileName, 'r') as fp:\n",
    "        return {ast.literal_eval(k): v for k, v in json.load(fp).items()}\n",
    "\n",
    "class HexLearner(object):\n",
    "    # This class is an implementation of the Q-Learning-Agent\n",
    "    # from Russel & Norvig (2010) p. 844\n",
    "    \n",
    "    def __init__(self, player, Q = {}, N = {}):\n",
    "        self.Q = Q\n",
    "        self.N = N\n",
    "        self.s = None\n",
    "        self.hash = None\n",
    "        self.a = None\n",
    "        self.r = None\n",
    "        self.player = player\n",
    "        self.actions = [0, 1, 2, 3, 4]\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, player):\n",
    "        return cls(player, loadFromFile(\"saves/P\" + str(player) + \"_Q.json\"), loadFromFile(\"saves/P\" + str(player) + \"_N.json\"))\n",
    "    \n",
    "    def save(self):\n",
    "        saveToFile(latestQ1, \"saves/P\" + str(self.player) + \"_Q.json\")\n",
    "        saveToFile(latestN1, \"saves/P\" + str(self.player) + \"_N.json\")\n",
    "    \n",
    "    def getMove(self, state, reward):\n",
    "        if gameEnded(state):\n",
    "            self.Q[getHash(state), None] = reward\n",
    "        if self.s is not None:\n",
    "            self.incrementN()\n",
    "            self.updateQ(state, reward)\n",
    "        self.s = state\n",
    "        self.hash = getHash(state)\n",
    "        self.a = self.argmax()\n",
    "        self.r = reward\n",
    "        return self.a\n",
    "    \n",
    "    def initializeQ(self, s, a):\n",
    "        if (s, a) not in self.Q:\n",
    "            self.Q[s, a] = 0\n",
    "    \n",
    "    def initializeN(self, s, a):\n",
    "        if (s, a) not in self.N:\n",
    "            self.N[s, a] = 0\n",
    "    \n",
    "    def argmax(self):\n",
    "        vals = []\n",
    "        s = self.hash\n",
    "        vals = [self.f(self.Q.get((s, a), 0), self.N.get((s, a), 0)) for a in self.actions]\n",
    "        return self.actions.index(vals.index(max(vals)))\n",
    "    \n",
    "    def f(self, val, num):\n",
    "        if num < 10:\n",
    "            return 100\n",
    "        return val\n",
    "    \n",
    "    def incrementN(self):\n",
    "        s = self.hash\n",
    "        a = self.a\n",
    "        self.initializeN(s, a)\n",
    "        self.N[s, a] += 1\n",
    "    \n",
    "    def updateQ(self, sP, rP):\n",
    "        s = self.hash\n",
    "        sPh = getHash(sP)\n",
    "        a = self.a\n",
    "        self.initializeQ(s, a)\n",
    "        self.Q[s, a] = self.Q[s, a] + self.alpha() * (self.r + max([self.Q.get((sPh, aP), 0) for aP in self.actions]) - self.Q[s, a])\n",
    "        \n",
    "    def alpha(self):\n",
    "        return 60 / (59 + self.N[self.hash, self.a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GreedyHexAgent(object):\n",
    "    def __init__(self, player):\n",
    "        self.player = player\n",
    "        self.actions = [0, 1, 2, 3, 4]\n",
    "        \n",
    "    def getMove(self, state, reward):\n",
    "        numOwnedCell = [self.cellsOwned(makeMove(state, self.player, a)) for a in self.actions]\n",
    "        return numOwnedCell.index(max(numOwnedCell))\n",
    "        \n",
    "    def cellsOwned(self, state):\n",
    "        return getHash(state).count('a' if self.player == 1 else 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    def getMove(self, state, reward):\n",
    "        return np.random.randint(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent is ready to learn! The code below lets the agent play against it self and learn along the way. We use a value $\\varepsilon$ to denote the probability of choosing a random action instead of the action supplied by the agent. This is done to force the agent to explore more. $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! - Played 10000 games. Took 93.55s. Saw 59880 states\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "NUMTRIALS = 10000\n",
    "EPSILON = 0.1\n",
    "latestQ1 = {}\n",
    "latestN1 = {}\n",
    "latestQ2 = {}\n",
    "latestN2 = {}\n",
    "\n",
    "startTime = time.time()\n",
    "startGame = randomGame(3, 3)\n",
    "\n",
    "for x in range(NUMTRIALS):\n",
    "    agent1 = HexLearner(1, latestQ1, latestN1)\n",
    "    agent2 = HexLearner(2, latestQ2, latestN2)\n",
    "    game = randomGame(3,3)\n",
    "    #game = startGame.copy()\n",
    "    while not gameEnded(game):\n",
    "        num = np.random.rand()\n",
    "        action = agent1.getMove(game, getReward(game, 1))\n",
    "        if num < EPSILON:\n",
    "            action = np.random.randint(5)\n",
    "        game = makeMove(game, 1, action)\n",
    "        \n",
    "        action = agent2.getMove(game, getReward(game, 2))\n",
    "        if num < EPSILON:\n",
    "            action = np.random.randint(5)\n",
    "        game = makeMove(game, 2, action)\n",
    "        \n",
    "    agent1.getMove(game, getReward(game, 1))\n",
    "    agent1.getMove(game, getReward(game, 1))\n",
    "    agent2.getMove(game, getReward(game, 2))\n",
    "    latestQ1 = agent1.Q\n",
    "    latestN1 = agent1.N\n",
    "    latestQ2 = agent2.Q\n",
    "    latestN2 = agent2.N\n",
    "\n",
    "agent1.save()\n",
    "agent2.save()\n",
    "print(\"\\nDone! - Played \" + str(NUMTRIALS) + \" games. Took \" + str(round(time.time() - startTime, 2)) + \"s. Saw \" + str(len(latestQ1)) + \" states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battle of the centuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 wins: 13.200000000000001%\n",
      "Player 2 wins: 86.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "GAMES = 10000\n",
    "\n",
    "\n",
    "\n",
    "player1wins = 0\n",
    "player2wins = 0\n",
    "for x in range(GAMES):\n",
    "    player1 = HexLearner(1, latestQ1, latestN1)\n",
    "    player2 = GreedyHexAgent(2)\n",
    "    game = randomGame(3, 3)\n",
    "    while not gameEnded(game):\n",
    "        action = player1.getMove(game, getReward(game, 1))\n",
    "        game = makeMove(game, 1, action)\n",
    "        if (gameEnded(game)):\n",
    "            player1wins += 1\n",
    "            continue\n",
    "        action = player2.getMove(game, 0)\n",
    "        game = makeMove(game, 2, action)\n",
    "        if (gameEnded(game)):\n",
    "            player2wins += 1\n",
    "\n",
    "print(\"Player 1 wins: \" + str(player1wins/GAMES*100) + \"%\")\n",
    "print(\"Player 2 wins: \" + str(player2wins/GAMES*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(latestQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 -1  3]\n",
      " [ 3  3  1]\n",
      " [ 3  2  4]\n",
      " [ 0  0 10]]\n",
      "P1: 3\n",
      "[[ 8 -1  8]\n",
      " [ 8  8  1]\n",
      " [ 8  2  4]\n",
      " [ 0  0 10]]\n",
      "4\n",
      "[[ 8 -1  8]\n",
      " [ 8  8  1]\n",
      " [ 8  2 14]\n",
      " [ 0  0 14]]\n",
      "P1: 0\n",
      "[[ 5 -1  5]\n",
      " [ 5  5  1]\n",
      " [ 5  2 14]\n",
      " [ 5  5 14]]\n",
      "2\n",
      "[[ 5 -1  5]\n",
      " [ 5  5  1]\n",
      " [ 5 12 12]\n",
      " [ 5  5 12]]\n",
      "P1: 1\n",
      "[[ 6 -1  6]\n",
      " [ 6  6  6]\n",
      " [ 6 12 12]\n",
      " [ 6  6 12]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7c74acf217bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeMove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P1 won!\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"P2 won!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = GreedyHexAgent(1)\n",
    "game = startGame.copy()\n",
    "print(game)\n",
    "\n",
    "while not gameEnded(game):\n",
    "    action = agent.getMove(game, getReward(game, 1))\n",
    "    if action != None:\n",
    "        print(\"P1: \" + str(action))\n",
    "        game = makeMove(game, 1, action)\n",
    "    print(game)\n",
    "    \n",
    "    game = makeMove(game, 2, int(input()))\n",
    "    print(game)\n",
    "print(\"P1 won!\" if getReward(game, 1) == 1 else \"P2 won!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
